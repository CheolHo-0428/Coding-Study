{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://www.alexa.com/topsites/countries/KR'\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, 'lxml')\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a href=\"/siteinfo/google.com\">Google.com</a>,\n",
       " <a href=\"/siteinfo/naver.com\">Naver.com</a>,\n",
       " <a href=\"/siteinfo/youtube.com\">Youtube.com</a>,\n",
       " <a href=\"/siteinfo/daum.net\">Daum.net</a>,\n",
       " <a href=\"/siteinfo/tistory.com\">Tistory.com</a>,\n",
       " <a href=\"/siteinfo/tmall.com\">Tmall.com</a>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Google.com'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking[1].get_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "website_ranking_address = [website_ranking_element.get_text() for\n",
    "                          website_ranking_element in website_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Google.com',\n",
       " 'Naver.com',\n",
       " 'Youtube.com',\n",
       " 'Daum.net',\n",
       " 'Tistory.com',\n",
       " 'Tmall.com']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "website_ranking_address[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top Sites in South Korea]\n",
      "1: this explanation\n",
      "2: Google.com\n",
      "3: Naver.com\n",
      "4: Youtube.com\n",
      "5: Daum.net\n",
      "6: Tistory.com\n"
     ]
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://www.alexa.com/topsites/countries/KR\"\n",
    "\n",
    "html_website_ranking = requests.get(url).text\n",
    "soup_website_ranking = BeautifulSoup(html_website_ranking, \"lxml\")\n",
    "\n",
    "# p 태그의 요소 안에서 a 태그의 요소를 찾음\n",
    "website_ranking = soup_website_ranking.select('p a')\n",
    "website_ranking_address = [website_ranking_element.get_text() for website_ranking_element in website_ranking]\n",
    "\n",
    "print(\"[Top Sites in South Korea]\")\n",
    "for k in range(6):\n",
    "    print(\"{0}: {1}\".format(k+1, website_ranking_address[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Website</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Google.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naver.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Youtube.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Daum.net</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Tistory.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Tmall.com</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Website\n",
       "2   Google.com\n",
       "3    Naver.com\n",
       "4  Youtube.com\n",
       "5     Daum.net\n",
       "6  Tistory.com\n",
       "7    Tmall.com"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "websote_ranking_dict = {'Website': website_ranking_address}\n",
    "df = pd.DataFrame(websote_ranking_dict, columns=['Website'],\n",
    "                 index=range(1,len(website_ranking_address)+1))\n",
    "df[1:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"ellipsis\">눈 (Feat. 이문세)</span>,\n",
       " <span class=\"ellipsis\">기억의 빈자리</span>,\n",
       " <span class=\"ellipsis\">선물</span>,\n",
       " <span class=\"ellipsis\">Beautiful</span>,\n",
       " <span class=\"ellipsis\">좋아</span>,\n",
       " <span class=\"ellipsis\">피카부 (Peek-A-Boo)</span>,\n",
       " <span class=\"ellipsis\">좋니</span>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url3 = 'https://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1'\n",
    "html_music = requests.get(url3).text\n",
    "soup_music = BeautifulSoup(html_music, 'lxml')\n",
    "\n",
    "titles = soup_music.select('a._title span.ellipsis')\n",
    "titles[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_titles = [title.get_text() for title in titles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['눈 (Feat. 이문세)', '기억의 빈자리', '선물', 'Beautiful', '좋아', '피카부 (Peek-A-Boo)', '좋니']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\r\\n\\t\\t\\t\\r\\n\\t\\t\\t\\r\\n\\t\\t\\tZion.T\\r\\n\\t\\t'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a 태그의 요소 중에서 class 속성값이 '_artist'인 것을 참고\n",
    "# 그 안에서 span 태그의 요소 중에서 class 속성값이 'ellipsis'인 요소를 추출\n",
    "artists = soup_music.select('a._artist span.ellipsis')\n",
    "artists[0].get_text()\n",
    "\n",
    "# \\r 리턴 / \\t 탭"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zion.T'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zion.T',\n",
       " '나얼',\n",
       " '멜로망스(Melomance)',\n",
       " 'Wanna One(워너원)',\n",
       " 'Red Velvet (레드벨벳)',\n",
       " '윤종신',\n",
       " '뉴이스트 W']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_artists[0:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# td 태그의 요소 중에서 class 속성값이 '_artist'인 것을 참고\n",
    "# 그 안에서 a 태그의 요소를 추출\n",
    "artists = soup_music.select('td._artist a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"_artist NPI=a:artist,r:1,i:115967\" href=\"/artist/home.nhn?artistId=115967\" title=\"Zion.T\">\n",
       "<span class=\"ellipsis\">\n",
       "\t\t\t\n",
       "\t\t\t\n",
       "\t\t\tZion.T\n",
       "\t\t</span>\n",
       "</a>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a alt=\"\" class=\"NPI=a:layerbtn,r:5\" href=\"javascript:void(0);\" title=\"\">민서</a>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Zion.T'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[0].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'민서'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4].get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_artists = [artist.get_text().strip() for artist in artists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zion.T',\n",
       " '나얼',\n",
       " '멜로망스(Melomance)',\n",
       " 'Wanna One(워너원)',\n",
       " '민서',\n",
       " 'Red Velvet (레드벨벳)',\n",
       " '윤종신']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_artists[0:7] # 민서, 윤종신을 뽑아서 insert로 4번에 넣어주세요~!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 눈 (Feat. 이문세) / Zion.T\n",
      "2: 기억의 빈자리 / 나얼\n",
      "3: 선물 / 멜로망스(Melomance)\n",
      "4: Beautiful / Wanna One(워너원)\n",
      "5: 좋아 / 민서\n",
      "6: 피카부 (Peek-A-Boo) / Red Velvet (레드벨벳)\n",
      "7: 좋니 / 윤종신\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=1\"    \n",
    "# url = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=2\"\n",
    "# url = \"http://music.naver.com/listen/top100.nhn?domain=TOTAL&page=1\"\n",
    "    \n",
    "html_music = requests.get(url).text\n",
    "soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "titles = soup_music.select('a._title span.ellipsis') \n",
    "artists = soup_music.select('td._artist a')\n",
    "\n",
    "music_titles = [title.get_text() for title in titles]\n",
    "music_artists = [artist.get_text().strip() for artist in artists]\n",
    "\n",
    "for k in range(7):\n",
    "    print(\"{0}: {1} / {2}\".format(k+1, music_titles[k], music_artists[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_titles_artists={}\n",
    "order = 0\n",
    "\n",
    "for (music_title, music_artist) in zip(music_titles, music_artists) :\n",
    "    order = order + 1\n",
    "    music_titles_artists[order] = [music_title, music_artist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['눈 (Feat. 이문세)', 'Zion.T']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles_artists[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['기억의 빈자리', '나얼']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_titles_artists[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/myPyCode/data/NaverMusicTop100.txt']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "    \n",
    "naver_music_url = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=\"\n",
    " \n",
    "# 네이버 music 주소를 입력하면 노래 제목과 아티스트를 반환\n",
    "def naver_music(url):    \n",
    "    html_music = requests.get(url).text\n",
    "    soup_music = BeautifulSoup(html_music, \"lxml\")\n",
    "\n",
    "    titles = soup_music.select('a._title span.ellipsis') \n",
    "    artists = soup_music.select('td._artist a')\n",
    "\n",
    "    music_titles = [title.get_text() for title in titles]\n",
    "    music_artists = [artist.get_text().strip() for artist in artists]\n",
    "    \n",
    "    return music_titles, music_artists\n",
    "\n",
    "# 노래 제목과 아티스트를 저장할 파일 이름을 폴더와 함께 지정\n",
    "file_name = 'C:/myPyCode/data/NaverMusicTop100.txt'\n",
    "\n",
    "f = open(file_name,'w') # 파일 열기\n",
    "\n",
    "# 각 page에는 50개의 노래 제목과 아티스트가 추출됨\n",
    "for page in range(2):\n",
    "    naver_music_url_page = naver_music_url + str(page+1) # page URL\n",
    "    naver_music_titles, naver_music_artists = naver_music(naver_music_url_page)\n",
    "    \n",
    "    # 추출된 노래 제목과 아티스트를 파일에 저장 \n",
    "    for k in range(len(naver_music_titles)):\n",
    "        f.write(\"{0:2d}: {1}/{2}\\n\".format(page*50 + k+1, naver_music_titles[k],  naver_music_artists[k]))\n",
    "        \n",
    "f.close() # 파일 닫기\n",
    "\n",
    "glob.glob(file_name) # 생성된 파일 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mission 1페이지 2페이지 따로 작성해서 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "naver_music_url1 = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=10&week=0'\n",
    "\n",
    "html_naver_music1 = requests.get(naver_music_url1).text\n",
    "soup_naver_music1 = BeautifulSoup(html_naver_music1, 'lxml')\n",
    "\n",
    "naver_titles1 = soup_naver_music1.select('a._title span.ellipsis')\n",
    "naver_artists1 = soup_naver_music1.select('td._artist a')\n",
    "\n",
    "naver_music_titles1 = [naver_title1.get_text() for naver_title1 in naver_titles1]\n",
    "naver_music_artists1 = [naver_artist1.get_text().strip() \n",
    "                        for naver_artist1 in naver_artists1]\n",
    "\n",
    "# for k in range(50) : \n",
    "#         print(f'{k+1}위: {naver_music_titles1[k]} / {naver_music_artists1[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "naver_music_url2 = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=10&week=0&page=2'\n",
    "\n",
    "html_naver_music2 = requests.get(naver_music_url2).text\n",
    "soup_naver_music2 = BeautifulSoup(html_naver_music2, 'lxml')\n",
    "\n",
    "naver_titles2 = soup_naver_music2.select('a._title span.ellipsis')\n",
    "naver_artists2 = soup_naver_music2.select('td._artist a')\n",
    "\n",
    "naver_music_titles2 = [naver_title2.get_text() for naver_title2 in naver_titles2]\n",
    "naver_music_artists2 = [naver_artist2.get_text().strip() \n",
    "                        for naver_artist2 in naver_artists2]\n",
    "\n",
    "# for k in range(50) : \n",
    "#         print(f'{51+k}위: {naver_music_titles2[k]} / {naver_music_artists2[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_naver_music_data1 = {'순위' : list(range(1,51)), \n",
    "                         'Title' : naver_music_titles1, \n",
    "                        'Artist' : naver_music_artists1}\n",
    "\n",
    "df1 = pd.DataFrame(excel_naver_music_data1, columns=['순위', 'Title', 'Artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "excel_naver_music_data2 = {'순위' : list(range(51,101)),\n",
    "                            'Title' : naver_music_titles2,\n",
    "                         'Artist' : naver_music_artists2}\n",
    "\n",
    "df2 = pd.DataFrame(excel_naver_music_data2, columns=['순위', 'Title', 'Artist'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>순위</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dynamite</td>\n",
       "      <td>방탄소년단</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Lovesick Girls</td>\n",
       "      <td>BLACKPINK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>DON'T TOUCH ME</td>\n",
       "      <td>환불원정대</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>취기를 빌려 (취향저격 그녀 X 산들)</td>\n",
       "      <td>산들</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>마리아 (Maria)</td>\n",
       "      <td>화사(Hwa Sa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>96</td>\n",
       "      <td>LALALILALA</td>\n",
       "      <td>에이프릴(APRIL)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>Criminal</td>\n",
       "      <td>태민(TAEMIN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>98</td>\n",
       "      <td>화려하지 않은 고백</td>\n",
       "      <td>규현(KYUHYUN)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>99</td>\n",
       "      <td>안녕</td>\n",
       "      <td>폴킴</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>100</td>\n",
       "      <td>You Never Know</td>\n",
       "      <td>BLACKPINK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     순위                  Title       Artist\n",
       "0     1               Dynamite        방탄소년단\n",
       "1     2         Lovesick Girls    BLACKPINK\n",
       "2     3         DON'T TOUCH ME        환불원정대\n",
       "3     4  취기를 빌려 (취향저격 그녀 X 산들)           산들\n",
       "4     5            마리아 (Maria)   화사(Hwa Sa)\n",
       "..  ...                    ...          ...\n",
       "95   96             LALALILALA  에이프릴(APRIL)\n",
       "96   97               Criminal   태민(TAEMIN)\n",
       "97   98             화려하지 않은 고백  규현(KYUHYUN)\n",
       "98   99                     안녕           폴킴\n",
       "99  100         You Never Know    BLACKPINK\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Total_rank = df1.append(df2, ignore_index = True)\n",
    "Total_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_writer = pd.ExcelWriter('c:/myPyCode/data/MUSIC100.xlsx', \n",
    "                              engine='xlsxwriter')\n",
    "Total_rank.to_excel(excel_writer, index = False)\n",
    "excel_writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mission 1페이지 2페이지 같이 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-9e77a47052b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mpage\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mnaver_music_url_page\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaver_music_url3\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpage\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mnaver_music_titles3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnaver_music_artists3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnaver_music\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnaver_music_url_page\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "\n",
    "naver_music_url3 = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=10&week=0&page='\n",
    "\n",
    "def naver_music(url3) :\n",
    "    html_naver_music3 = requests.get(naver_music_url3).text\n",
    "    soup_naver_music3 = BeautifulSoup(html_naver_music3, 'lxml')\n",
    "    \n",
    "    naver_titles3 = soup_naver_music3.select('a._title span.ellipsis')\n",
    "    naver_artists3 = soup_naver_music3.select('td._artist a')\n",
    "    \n",
    "    naver_music_titles3 = [naver_title3.get_text() for naver_title3 in naver_titles3]\n",
    "    naver_music_artists3 = [naver_artist3.get_text().strip() \n",
    "                            for naver_artist3 in naver_artists3]\n",
    "\n",
    "for page in range(2) :\n",
    "    naver_music_url_page = naver_music_url3 + str(page+1)\n",
    "    naver_music_titles3, naver_music_artists3 = naver_music(naver_music_url_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(2) :\n",
    "    naver_music_url_page = naver_music_url3 + str(page+1)\n",
    "    naver_music_titles3, naver_music_artists3 = naver_music(naver_music_url_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "naver_music_url = 'https://music.naver.com/listen/history/index.nhn?type=TOTAL_V2&year=2020&month=10&week=0&page='\n",
    "\n",
    "for page in range(2) :\n",
    "    if page == 0 :\n",
    "        naver_music_url_page = naver_music_url + str(page+1)\n",
    "     \n",
    "        html_naver_music = requests.get(naver_music_url_page).text\n",
    "        soup_naver_music = BeautifulSoup(html_naver_music, 'lxml')\n",
    "\n",
    "        naver_titles = soup_naver_music.select('a._title span.ellipsis')\n",
    "        naver_artists = soup_naver_music.select('td._artist a')\n",
    "\n",
    "        naver_music_titles = [naver_title.get_text() for naver_title in naver_titles]\n",
    "        naver_music_artists = [naver_artist.get_text().strip() for naver_artist in naver_artists]\n",
    "    \n",
    "    else :\n",
    "        naver_music_url_page = naver_music_url + str(page+1)\n",
    "     \n",
    "        html_naver_music = requests.get(naver_music_url_page).text\n",
    "        soup_naver_music = BeautifulSoup(html_naver_music, 'lxml')\n",
    "\n",
    "        naver_titles = soup_naver_music.select('a._title span.ellipsis')\n",
    "        naver_artists = soup_naver_music.select('td._artist a')\n",
    "\n",
    "        naver_music_titles = [naver_title.get_text() for naver_title in naver_titles]\n",
    "        naver_music_artists = [naver_artist.get_text().strip() for naver_artist in naver_artists]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Dynamite',\n",
       "  'Lovesick Girls',\n",
       "  \"DON'T TOUCH ME\",\n",
       "  '취기를 빌려 (취향저격 그녀 X 산들)',\n",
       "  '마리아 (Maria)',\n",
       "  'When We Disco (Duet with 선미)',\n",
       "  '에잇(Prod.&Feat. SUGA of BTS)',\n",
       "  '눈누난나 (NUNU NANA)',\n",
       "  'Dolphin',\n",
       "  'How You Like That',\n",
       "  'Savage Love (Laxed - Siren Beat) (BTS Remix)',\n",
       "  'Ice Cream (with Selena Gomez)',\n",
       "  '어떻게 이별까지 사랑하겠어, 널 사랑하는 거지',\n",
       "  'Not Shy',\n",
       "  '다시 여기 바닷가',\n",
       "  '덤디덤디 (DUMDi DUMDi)',\n",
       "  '내 마음이 움찔했던 순간 (취향저격 그녀 X 규현)',\n",
       "  '살짝 설렜어 (Nonstop)',\n",
       "  '아로하',\n",
       "  '홀로',\n",
       "  'Bet You Wanna (Feat. Cardi B)',\n",
       "  '흔들리는 꽃들 속에서 네 샴푸향이 느껴진거야',\n",
       "  'Blueming',\n",
       "  'Love poem',\n",
       "  '보라빛 밤 (pporappippam)',\n",
       "  'Downtown Baby',\n",
       "  '사랑하게 될 줄 알았어',\n",
       "  '늦은 밤 너의 집 앞 골목길에서',\n",
       "  'Memories',\n",
       "  '힘든 건 사랑이 아니다',\n",
       "  '숲의 아이 (Bon voyage)',\n",
       "  '오래된 노래',\n",
       "  'Psycho',\n",
       "  '밤편지',\n",
       "  'METEOR',\n",
       "  'Bad Boy',\n",
       "  'Pretty Savage',\n",
       "  '거짓말이라도 해서 널 보고싶어',\n",
       "  '너를 만나',\n",
       "  '2002',\n",
       "  'Dance Monkey',\n",
       "  \"Don't Start Now\",\n",
       "  '그 여름을 틀어줘',\n",
       "  'PLAY (Feat. 창모)',\n",
       "  '모든 날, 모든 순간 (Every day, Every Moment)',\n",
       "  'Holy (Feat. Chance The Rapper)',\n",
       "  'Watermelon Sugar',\n",
       "  '아무노래',\n",
       "  'Summer Hate (Feat. 비)',\n",
       "  'ALIEN']]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "naver_music_titles50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_naver_music_data = {'순위' : list(range(1,101)), \n",
    "                         'Title' : naver_music_titles100, \n",
    "                        'Artist' : naver_music_artists100}\n",
    "\n",
    "df1 = pd.DataFrame(excel_naver_music_data, columns=['순위', 'Title', 'Artist'])\n",
    "\n",
    "Total_rank = df1(ignore_index = True)\n",
    "Total_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "459!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 페이지 1,2 같이 보이기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: 눈 (Feat. 이문세) / Zion.T\n",
      "2: 기억의 빈자리 / 나얼\n",
      "3: 선물 / 멜로망스(Melomance)\n",
      "4: Beautiful / Wanna One(워너원)\n",
      "5: 좋아 / 민서\n",
      "6: 피카부 (Peek-A-Boo) / Red Velvet (레드벨벳)\n",
      "7: 좋니 / 윤종신\n",
      "-----------------------------------------\n",
      "51: 가시나 / 선미\n",
      "52: all of my life / 박원\n",
      "53: To Be One (Outro.) / Wanna One(워너원)\n",
      "54: 비행운 / 문문(MoonMoon)\n",
      "55: 고민보다 Go / 방탄소년단\n",
      "56: 빨간 맛 (Red Flavor) / Red Velvet (레드벨벳)\n",
      "57: 덜덜덜 / EXID\n",
      "58: 밤이 되니까 / 펀치 (Punch)\n",
      "59: 피 땀 눈물 / 방탄소년단\n",
      "60: Blue / 볼빨간사춘기\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url1to50 = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=1\"    \n",
    "url51to100 = \"http://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year=2017&month=12&week=1&page=2\"\n",
    "# url = \"http://music.naver.com/listen/top100.nhn?domain=TOTAL&page=1\"\n",
    "# url = \"http://music.naver.com/listen/top100.nhn?domain=TOTAL&page=2\"\n",
    "    \n",
    "html_music1to50 = requests.get(url1to50).text\n",
    "soup_music1to50 = BeautifulSoup(html_music1to50, \"lxml\")\n",
    "\n",
    "titles1to50 = soup_music1to50.select('a._title span.ellipsis') \n",
    "artists1to50 = soup_music1to50.select('td._artist a')\n",
    "\n",
    "music_titles1to50 = [title.get_text() for title in titles1to50]\n",
    "music_artists1to50 = [artist.get_text().strip() for artist in artists1to50 ]\n",
    "\n",
    "for k in range(7):\n",
    "    print(\"{0}: {1} / {2}\".format(k+1, music_titles1to50[k], music_artists1to50[k]))\n",
    "\n",
    "print(\"-----------------------------------------\")\n",
    "\n",
    "html_music51to100 = requests.get(url51to100).text\n",
    "soup_music51to100 = BeautifulSoup(html_music51to100, \"lxml\")\n",
    "\n",
    "titles51to100 = soup_music51to100.select('a._title span.ellipsis') \n",
    "artists51to100 = soup_music51to100.select('td._artist a')\n",
    "\n",
    "music_titles51to100 = [title.get_text() for title in titles51to100]\n",
    "music_artists51to100 = [artist.get_text().strip() for artist in artists51to100]\n",
    "   \n",
    "num = 50\n",
    "for k in range(10):\n",
    "    print(str(num+1)+\": {0} / {1}\".format(music_titles51to100[k], music_artists51to100[k]))\n",
    "    num=num+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 연도, 월, 주를 입력해서 뽑기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "연도를 입력하세요 : 2017\n",
      "월을 입력하세요 : 4\n",
      "주를 입력하세요 : 3\n",
      "[Top 10 in Naver Music]\n",
      "1 : 사랑이 잘 (With 오혁)\n",
      "2 : 팔레트 (Feat. G-DRAGON)\n",
      "3 : 밤편지\n",
      "4 : REALLY REALLY\n",
      "5 : She's a Baby\n",
      "6 : 얼굴 찌푸리지 말아요\n",
      "7 : 첫눈처럼 너에게 가겠다\n",
      "8 : KNOCK KNOCK\n",
      "9 : Marry Me\n",
      "10 : 이런 엔딩\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "year = input('연도를 입력하세요 : ')\n",
    "month = input('월을 입력하세요 : ')\n",
    "week = input('주를 입력하세요 : ')\n",
    "\n",
    "if len(month) == 1:\n",
    "    month = \"0\"+month\n",
    "else:\n",
    "    month = month\n",
    "\n",
    "url3 = (f'https://music.naver.com/listen/history/index.nhn?type=DOMESTIC&year={year}&month={month}&week={week}')\n",
    "html_music = requests.get(url3).text\n",
    "soup_music = BeautifulSoup(html_music, 'lxml')\n",
    "\n",
    "titles = soup_music.select('a._title span.ellipsis')\n",
    "\n",
    "music_ranking_address = [music_ranking_element.get_text() for\n",
    "                          music_ranking_element in titles]\n",
    "\n",
    "print(\"[Top 10 in Naver Music]\")\n",
    "for k in range(10):\n",
    "    print(f\"{k+1} : {music_ranking_address[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MISSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://music.naver.com/listen/top100.nhn?domain=TOTAL'\n",
    "\n",
    "html_music_ranking = requests.get(url).text\n",
    "soup_music_ranking = BeautifulSoup(html_music_ranking, 'lxml')\n",
    "\n",
    "music_ranking = soup_music_ranking.select('td.name a span.ellipsis ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<span class=\"ellipsis\">Dynamite</span>,\n",
       " <span class=\"ellipsis\">Lovesick Girls</span>,\n",
       " <span class=\"ellipsis\">DON'T TOUCH ME</span>,\n",
       " <span class=\"ellipsis\">잠이 오질 않네요</span>,\n",
       " <span class=\"ellipsis\">취기를 빌려 (취향저격 그녀 X 산들)</span>,\n",
       " <span class=\"ellipsis\">힘든 건 사랑이 아니다</span>,\n",
       " <span class=\"ellipsis\">I CAN'T STOP ME</span>,\n",
       " <span class=\"ellipsis\">Savage Love (Laxed - Siren Beat) (BTS Remix)</span>,\n",
       " <span class=\"ellipsis\">딩가딩가 (Dingga)</span>,\n",
       " <span class=\"ellipsis\">마리아 (Maria)</span>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_ranking[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "music_ranking_address = [music_ranking_element.get_text() for\n",
    "                          music_ranking_element in music_ranking]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dynamite',\n",
       " 'Lovesick Girls',\n",
       " \"DON'T TOUCH ME\",\n",
       " '잠이 오질 않네요',\n",
       " '취기를 빌려 (취향저격 그녀 X 산들)',\n",
       " '힘든 건 사랑이 아니다',\n",
       " \"I CAN'T STOP ME\",\n",
       " 'Savage Love (Laxed - Siren Beat) (BTS Remix)',\n",
       " '딩가딩가 (Dingga)',\n",
       " '마리아 (Maria)']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music_ranking_address[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Top 10 in Naver Music]\n",
      "1위 : Dynamite\n",
      "2위 : Lovesick Girls\n",
      "3위 : DON'T TOUCH ME\n",
      "4위 : 잠이 오질 않네요\n",
      "5위 : 취기를 빌려 (취향저격 그녀 X 산들)\n",
      "6위 : 힘든 건 사랑이 아니다\n",
      "7위 : I CAN'T STOP ME\n",
      "8위 : Savage Love (Laxed - Siren Beat) (BTS Remix)\n",
      "9위 : 딩가딩가 (Dingga)\n",
      "10위 : 마리아 (Maria)\n"
     ]
    }
   ],
   "source": [
    "print(\"[Top 10 in Naver Music]\")\n",
    "for k in range(10):\n",
    "    print(f'{k+1}위 : {music_ranking_address[k]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "url = \"https://music.naver.com/listen/top100.nhn?domain=TOTAL_V2\"\n",
    "\n",
    "html_music_ranking = requests.get(url).text\n",
    "soup_music_ranking = BeautifulSoup(html_music_ranking, \"lxml\")\n",
    "\n",
    "music_ranking = soup_music_ranking.select('a._title')\n",
    "\n",
    "music_ranking_address = []\n",
    "\n",
    "for music_ranking_element in music_ranking:\n",
    "    music_ranking_address.append(music_ranking_element.get_text())\n",
    "\n",
    "print(\"[Top 10 in Naver Music]\")\n",
    "for k in range(10):\n",
    "    # print(\"{0}: {1}\".format(k+1, music_ranking_address[k]))\n",
    "    print(f\"{k+1} {music_ranking_address[k]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 웹 페이지에서 이미지 가져오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 하나의 이미지 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://www.python.org/static/img/python-logo@2x.png'\n",
    "html_image = requests.get(url)\n",
    "html_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'python-logo@2x.png'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "image_file_name = os.path.basename(url)\n",
    "image_file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder = 'c:/myPyCode/download'\n",
    "\n",
    "if not os.path.exists(folder) :\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:/myPyCode/download\\\\python-logo@2x.png'"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_path = os.path.join(folder, image_file_name)\n",
    "image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageFile = open(image_path, 'wb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size) :\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['051ff3fb781ff83c9b0f8a32f9922fa6.png', 'python-logo@2x.png']"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['051ff3fb781ff83c9b0f8a32f9922fa6.png', '200937431.jpg', 'python-logo@2x.png']"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "url = 'https://blog.jinbo.net/attach/615/200937431.jpg'\n",
    "html_image = requests.get(url)\n",
    "image_file_name = os.path.basename(url)\n",
    "folder = 'c:/myPyCode/download'\n",
    "\n",
    "if not os.path.exists(folder) :\n",
    "    os.makedirs(folder)\n",
    "    \n",
    "image_path = os.path.join(folder, image_file_name)\n",
    "imageFile = open(image_path, 'wb')\n",
    "\n",
    "chunk_size = 1000000\n",
    "for chunk in html_image.iter_content(chunk_size) :\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()\n",
    "\n",
    "os.listdir(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 여러 이미지 내려받기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<img alt=\"Reshot navbar logo\" class=\"black\" src=\"https://assets-static.reshot-cdn.com/brand/reshot-logo.png\"/>,\n",
       " <img alt=\"Free authentic animal photo on Reshot\" src=\"https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg\"/>,\n",
       " <img alt=\"Back off!\" src=\"https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1597098233/photosp/a44357c5-b1c3-41ef-9a65-7a4937b06a44/a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg\"/>,\n",
       " <img alt='\"Orphans\"' src=\"https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1597098206/photosp/34fd9c70-8996-4706-a0f1-113231ed3eee/34fd9c70-8996-4706-a0f1-113231ed3eee.jpg\"/>]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests  \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "URL = 'https://www.reshot.com/search/animal'\n",
    "\n",
    "html_reshot_image = requests.get(URL).text\n",
    "# print(html_pixabay_image)\n",
    "\n",
    "\n",
    "soup_reshot_image = BeautifulSoup(html_reshot_image, \"lxml\")\n",
    "# print(soup_pixabay_image)\n",
    "\n",
    "reshot_image_elements = soup_reshot_image.select('a img') \n",
    "reshot_image_elements[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://res.cloudinary.com/twenty20/private_images/t_standard-fit/v1521838685/photosp/bae96789-a5ab-4471-b54f-9686ace09e33/bae96789-a5ab-4471-b54f-9686ace09e33.jpg'"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshot_image_url = reshot_image_elements[1].get('src')\n",
    "reshot_image_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_image = requests.get(reshot_image_url)\n",
    "\n",
    "folder = \"C:/myPyCode/download\"\n",
    "    \n",
    "# os.path.basename(URL)는 웹사이트나 폴더가 포함된 파일명에서 파일명만 분리하는 방법    \n",
    "imageFile = open(os.path.join(folder, os.path.basename(reshot_image_url)), 'wb')\n",
    "\n",
    "# 이미지 데이터를 1000000 바이트씩 나눠서 저장하는 방법\n",
    "chunk_size = 1000000 \n",
    "for chunk in html_image.iter_content(chunk_size):\n",
    "    imageFile.write(chunk)\n",
    "imageFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "이미지 파일명 : 'reshot-logo.png'.내려받기 완료!\n",
      "이미지 파일명 : 'bae96789-a5ab-4471-b54f-9686ace09e33.jpg'.내려받기 완료!\n",
      "이미지 파일명 : 'a44357c5-b1c3-41ef-9a65-7a4937b06a44.jpg'.내려받기 완료!\n",
      "이미지 파일명 : '34fd9c70-8996-4706-a0f1-113231ed3eee.jpg'.내려받기 완료!\n",
      "이미지 파일명 : 'dbd9fa3b-238b-47b1-8e20-c05400cbe921.jpg'.내려받기 완료!\n",
      "이미지 파일명 : '737d192f-ba38-4a71-9bb9-9d40b45d0263.jpg'.내려받기 완료!\n",
      "이미지 파일명 : 'c3c3604d-36eb-4f8a-9768-cebc0749d5a5.jpg'.내려받기 완료!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# URL(주소)에서 이미지 주소 추출\n",
    "def get_image_url(url) :\n",
    "    html_image_url = requests.get(url).text\n",
    "    soup_image_url = BeautifulSoup(html_image_url, 'lxml')\n",
    "    image_elements = soup_image_url.select('a img')\n",
    "    if(image_elements != None) :\n",
    "        image_urls =[]\n",
    "        for image_element in image_elements :\n",
    "            image_urls.append(image_element.get('src'))\n",
    "        return image_urls\n",
    "    else :\n",
    "        return None\n",
    "    \n",
    "# 폴더를 지정해 이미지 주소에서 이미지 내려받기\n",
    "def download_image(img_folder, img_url):\n",
    "    if(img_url != None) :\n",
    "        html_image = requests.get(img_url)\n",
    "        imageFile = open(os.path.join(img_folder, os.path.basename(img_url)), 'wb')\n",
    "        \n",
    "        chunk_size = 1000000\n",
    "        for chunk in html_image.iter_content(chunk_size) :\n",
    "            imageFile.write(chunk)\n",
    "            imageFile.close()\n",
    "        print(\"이미지 파일명 : '{0}'.내려받기 완료!\".format(os.path.basename(img_url)))\n",
    "    else :\n",
    "        print('내려받을 이미지가 없습니다.')\n",
    "        \n",
    "# 웹 사이트의 주소 지정\n",
    "reshot_url = 'https://www.reshot.com/search/animal'\n",
    "\n",
    "figure_folder = 'c:/myPyCode/download'\n",
    "\n",
    "if not os.path.exists(figure_folder):\n",
    "    os.makedirs(figure_folder)\n",
    "\n",
    "reshot_image_urls = get_image_url(reshot_url)\n",
    "\n",
    "num_of_download_image = 7\n",
    "\n",
    "for k in range(num_of_download_image) :\n",
    "    download_image(figure_folder,reshot_image_urls[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_download_image = len(reshot_image_urls)\n",
    "num_of_download_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### mission 네이버에서 사진 다운로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS 패키지, 사진을 저장\n",
    "\n",
    "import time\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(\"c:/chromedriver\")\n",
    "\n",
    "# 명시적으로 홈페이가 뜨기 전까지 기다려 줌(네트워크 상황에 따라 3초 전에 들어오면 실행)\n",
    "driver.implicitly_wait(3)\n",
    "driver.get(\"https://www.naver.com/\") \n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "html = driver.page_source\n",
    "html_parsing = BeautifulSoup(html, \"lxml\")\n",
    "\n",
    "# 프로그래스바 \n",
    "from tqdm import tqdm\n",
    "\n",
    "# 네이버 검색 키워드\n",
    "keyword = \"블랙핑크\"\n",
    "\n",
    "# 중간중간 잘 동작되는지 확인\n",
    "print(\"접속중\")\n",
    "\n",
    "url = \"https://search.naver.com/search.naver?where=image&sm=tab_jum&query={}\".format(keyword)\n",
    "driver.get(url)\n",
    "\n",
    "page_count = 30\n",
    "for i in range(page_count):\n",
    "    SCROLL_PAUSE_SEC = 2\n",
    "\n",
    "    # 스크롤 높이 가져옴\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    while True:\n",
    "        # 끝까지 스크롤 다운\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "        # 1초 대기\n",
    "        time.sleep(SCROLL_PAUSE_SEC)\n",
    "\n",
    "        # 스크롤 다운 후 스크롤 높이 다시 가져옴\n",
    "        new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "        last_height = new_height    \n",
    "    \n",
    "imgs = driver.find_elements_by_css_selector(\"img._img\")\n",
    "# print(imgs)\n",
    "\n",
    "result = []\n",
    "\n",
    "for img in imgs:\n",
    "    if 'http' in img.get_attribute('src'):\n",
    "        result.append(img.get_attribute('src'))\n",
    "    \n",
    "# print(result)\n",
    "\n",
    "driver.close()\n",
    "print(\"수집완료\")\n",
    "\n",
    "# OS\n",
    "import os\n",
    "\n",
    "if not os.path.isdir(\"./{}\".format(keyword)):\n",
    "    os.mkdir(\"./{}\".format(keyword))\n",
    "else:\n",
    "    print(\"폴더가 있습니다.\")\n",
    "\n",
    "print(\"크롤링한 사진을 폴더에 넣습니다.\")\n",
    "\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "for idx, link in tqdm(enumerate(result)):\n",
    "    start = link.rfind('.')\n",
    "    end = link.rfind('&')\n",
    "    filetype = link[start:end]\n",
    "    \n",
    "    urlretrieve(link, './{}/{}{}{}'.format(keyword, keyword, idx, filetype))\n",
    "\n",
    "print(\"이미지 크롤링 완료\")\n",
    "\n",
    "# 압축\n",
    "import zipfile\n",
    "\n",
    "zip_file_result = zipfile.ZipFile('./{}.zip'.format(keyword),'w')\n",
    "\n",
    "for image in os.listdir('./{}'.format(keyword)):\n",
    "    print(image, \"압축파일에 추가\")\n",
    "    zip_file_result.write('./{}/{}'.format(keyword, image), compress_type=zipfile.ZIP_DEFLATED)\n",
    "    \n",
    "zip_file_result.close()\n",
    "print(\"압축 완료\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
